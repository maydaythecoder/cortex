// Neural Network Example in Cortex
// Multi-layer perceptron for classification

// Constants
let INPUT_SIZE :: 784
let HIDDEN_SIZE :: 128
let OUTPUT_SIZE :: 10
let BATCH_SIZE :: 32
let LEARNING_RATE :: 0.001
let EPOCHS :: 50

// Neural Network Layer
struct Layer |
  weights: tensor
  bias: tensor
  activation: string
^

// Neural Network Model
struct NeuralNetwork |
  layers: list[Layer]
  optimizer: string
^

// Create a dense layer
func create_dense_layer[input_size: int, output_size: int, activation: string] -> Layer |
  let layer := Layer{
    weights: randn[input_size, output_size] * 0.1,
    bias: zeros[output_size],
    activation: activation
  }
  return[layer]
^

// Initialize neural network
func create_neural_network[input_size: int, hidden_size: int, output_size: int] -> NeuralNetwork |
  let layers := [
    create_dense_layer[input_size, hidden_size, "relu"],
    create_dense_layer[hidden_size, output_size, "softmax"]
  ]
  
  return[NeuralNetwork{
    layers: layers,
    optimizer: "adam"
  }]
^

// Forward pass through a single layer
func forward_layer[layer: Layer, input: tensor] -> tensor |
  let output := input @ layer.weights + layer.bias
  
  match [layer.activation] |
    case ["relu"] -> return[relu[output]]
    case ["sigmoid"] -> return[sigmoid[output]]
    case ["softmax"] -> return[softmax[output]]
    case ["tanh"] -> return[tanh[output]]
    default -> return[output]
  ^
^

// Forward pass through entire network
func forward_pass[model: NeuralNetwork, input: tensor] -> tensor |
  let output := input
  
  for [layer in model.layers] |
    output := forward_layer[layer, output]
  ^
  
  return[output]
^

// Cross-entropy loss
func cross_entropy_loss[predictions: tensor, targets: tensor] -> float |
  let epsilon := 1e-8
  let clipped_preds := clip[predictions, epsilon, 1.0 - epsilon]
  return[-mean[targets * log[clipped_preds]]]
^

// One-hot encoding
func one_hot[labels: tensor, num_classes: int] -> tensor |
  let batch_size := len[labels]
  let encoded := zeros[batch_size, num_classes]
  
  for [i in range[0, batch_size]] |
    encoded[i, labels[i]] := 1.0
  ^
  
  return[encoded]
^

// Training step
func train_step[model: NeuralNetwork, batch_inputs: tensor, batch_targets: tensor, lr: float] -> float |
  // Forward pass
  let predictions := forward_pass[model, batch_inputs]
  
  // Compute loss
  let loss := cross_entropy_loss[predictions, batch_targets]
  
  // Backward pass (simplified - in practice, use autograd)
  let gradients := âˆ‡[loss, model.parameters]
  
  // Update parameters (simplified SGD)
  for [layer in model.layers] |
    layer.weights := layer.weights - lr * gradients.weights
    layer.bias := layer.bias - lr * gradients.bias
  ^
  
  return[loss]
^

// Training function
func train_neural_network[model: NeuralNetwork, train_data: dict, val_data: dict] |
  let train_inputs := train_data["inputs"]
  let train_labels := train_data["labels"]
  let val_inputs := val_data["inputs"]
  let val_labels := val_data["labels"]
  
  // Convert labels to one-hot
  let train_targets := one_hot[train_labels, OUTPUT_SIZE]
  let val_targets := one_hot[val_labels, OUTPUT_SIZE]
  
  print["Starting neural network training..."]
  print["Training samples: " + str[len[train_inputs]]]
  print["Validation samples: " + str[len[val_inputs]]]
  
  // Training loop
  for [epoch in range[0, EPOCHS]] |
    let epoch_loss := 0.0
    let num_batches := 0
    
    // Process batches
    for [batch_start in range[0, len[train_inputs], BATCH_SIZE]] |
      let batch_end := min[batch_start + BATCH_SIZE, len[train_inputs]]
      let batch_inputs := train_inputs[batch_start:batch_end]
      let batch_targets := train_targets[batch_start:batch_end]
      
      // Training step
      let batch_loss := train_step[model, batch_inputs, batch_targets, LEARNING_RATE]
      epoch_loss := epoch_loss + batch_loss
      num_batches := num_batches + 1
    ^
    
    let avg_train_loss := epoch_loss / num_batches
    
    // Validation
    let val_predictions := forward_pass[model, val_inputs]
    let val_loss := cross_entropy_loss[val_predictions, val_targets]
    
    // Compute accuracy
    let train_pred_labels := argmax[forward_pass[model, train_inputs], axis=1]
    let val_pred_labels := argmax[val_predictions, axis=1]
    
    let train_acc := accuracy_score[train_pred_labels, train_labels]
    let val_acc := accuracy_score[val_pred_labels, val_labels]
    
    // Print progress
    if [epoch % 5 == 0] |
      print["Epoch " + str[epoch] + ": " +
            "Train Loss = " + str[avg_train_loss] + ", " +
            "Val Loss = " + str[val_loss] + ", " +
            "Train Acc = " + str[train_acc] + ", " +
            "Val Acc = " + str[val_acc]]
    ^
  ^
  
  print["Training completed!"]
^
^

// Generate synthetic data
func generate_classification_data[n_samples: int, n_features: int, n_classes: int] |
  let X := randn[n_samples, n_features]
  let y := randint[n_samples, 0, n_classes]
  
  return[{"inputs": X, "labels": y}]
^

// Main execution
func main[] |
  print["=== Neural Network in Cortex ==="]
  
  // Create model
  let model := create_neural_network[INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE]
  print["Created neural network with " + str[len[model.layers]] + " layers"]
  
  // Generate synthetic data
  let train_data := generate_classification_data[1000, INPUT_SIZE, OUTPUT_SIZE]
  let val_data := generate_classification_data[200, INPUT_SIZE, OUTPUT_SIZE]
  
  // Train the model
  train_neural_network[model, train_data, val_data]
  
  // Test on new data
  let test_data := generate_classification_data[50, INPUT_SIZE, OUTPUT_SIZE]
  let test_predictions := forward_pass[model, test_data["inputs"]]
  let test_pred_labels := argmax[test_predictions, axis=1]
  
  print["Test accuracy: " + str[accuracy_score[test_pred_labels, test_data["labels"]]]]
^
